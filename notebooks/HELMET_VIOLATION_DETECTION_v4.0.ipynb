{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "<h1 align=center><font size = 5>CAPSTONE PROJECT</font></h1>\n",
    "<h2 align=center><font size = 5>AIML Certification Programme</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Student Name and ID:\n",
    "Mention your name and ID if done individually<br>\n",
    "If done as a group,clearly mention the contribution from each group member qualitatively and as a precentage.<br>\n",
    "1. KUNA MURALI (ID: 2024AIML030)                          \n",
    "\n",
    "2. MADIRE MAHESHKUMAR (ID: 2024AIML079)\n",
    "\n",
    "3. V VIJAY KUMAR (ID: 2024AIML100)\n",
    "\n",
    "4. GADIGA MOUNESWAR BABU (ID: 2024AIML095)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helmet Violation Detection from Indian CCTV Video\n",
    "\n",
    "**Problem statement:**\n",
    "    Detect and flag two-wheeler helmet violations (helmetless riding) from traffic camera frames in Indian cities in real-time.\n",
    "\n",
    "**Description:**\n",
    "Create a computer vision system using YOLOv8 and object tracking to detect two-wheeler riders and classify helmet usage. Optionally perform license plate OCR for enforcement.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "    •\tIndian Helmet Detection Dataset\n",
    "    \n",
    "    •\tResearch-generated dataset of Indian two-wheeler violations (images+video with annotations for helmet & plate) \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python==4.9.0.80\n",
    "!pip install matplotlib==3.8.4\n",
    "!pip install numpy==1.26.4\n",
    "!pip install pillow==10.3.0\n",
    "!pip install pandas==2.2.2\n",
    "!pip install seaborn==0.13.2\n",
    "!pip install scikit-learn==1.4.2\n",
    "!pip install torch==2.3.0\n",
    "!pip install notebook==7.2.0\n",
    "!pip install albumentations==1.4.8\n",
    "!pip install albucore==0.0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter\n",
    "import albumentations as A\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts'))\n",
    "sys.path.append(scripts_dir)\n",
    "for entry in os.listdir(scripts_dir):\n",
    "    entry_path = os.path.join(scripts_dir, entry)\n",
    "    if os.path.isdir(entry_path):\n",
    "        sys.path.append(entry_path)\n",
    "\n",
    "from utils import show_images_grid\n",
    "from flip import HorizontalFlip\n",
    "from zoom import DynamicZoomer\n",
    "from mosaic import MosaicAugmentor\n",
    "from cutout import CutoutAugmentor\n",
    "from synthetic import SyntheticImageAugmentor\n",
    "from edgedetect import EdgeDetectAugmentor\n",
    "from cutmix import CutMixAugmentor\n",
    "from rotate import RotateAugmentor\n",
    "from shadow import ShadowCastingAugmentor\n",
    "from grayscale import GrayscaleAugmentor\n",
    "from noise import NoiseInjectionAugmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Dataset Structure & Counts</h3>\n",
    "\n",
    " *  Number of images in total.\n",
    "\n",
    " *  Number of labels (bounding boxes).\n",
    "\n",
    " *  Distribution of classes (e.g., how many helmet, person, motorbike).\n",
    "\n",
    " *  Check if all images have corresponding labels (sometimes labels are missing).\n",
    "\n",
    " *  Check for duplicate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"..\\\\data\\\\raw\\\\train\\\\images\"\n",
    "label_folder = \"..\\\\data\\\\raw\\\\train\\\\labels\"\n",
    "\n",
    "class_map = {\n",
    "    0: \"NumberPlate\",\n",
    "    1: \"Person\",\n",
    "    2: \"Helmet\",\n",
    "    3: \"Head\",\n",
    "    4: \"Motorbike\"\n",
    "}\n",
    "\n",
    "images = os.listdir(image_folder)\n",
    "labels = os.listdir(label_folder)\n",
    "\n",
    "\n",
    "print(\"Total images:\", len(images))\n",
    "print(\"Total label files:\", len(labels))\n",
    "print(\"Missing label files:\", set(os.path.splitext(i)[0] for i in images) - set(os.path.splitext(l)[0] for l in labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Total **800** images in **training dataset** and its corresponding label files. \n",
    "\n",
    "Note: No image has missing corresponding label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count classes\n",
    "class_counts = {}\n",
    "\n",
    "# Walk through all label files\n",
    "for lbl_name in os.listdir(label_folder):\n",
    "    if not lbl_name.endswith(\".txt\"):\n",
    "        continue\n",
    "    with open(os.path.join(label_folder, lbl_name), \"r\") as f:\n",
    "        for line in f:\n",
    "            cls = int(line.strip().split()[0])\n",
    "            class_counts[cls] = class_counts.get(cls, 0) + 1\n",
    "\n",
    "# Replace class IDs with names for plotting\n",
    "labels = [class_map.get(k, str(k)) for k in class_counts.keys()]\n",
    "counts = list(class_counts.values())\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(labels, counts, color=\"skyblue\", edgecolor=\"black\")\n",
    "\n",
    "# Add numbers on top of bars\n",
    "for rect in bars:\n",
    "    height = rect.get_height()\n",
    "    ax.annotate(f'{int(height)}',\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # vertical spacing\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_xlabel(\"Class\")\n",
    "ax.set_ylabel(\"Number of objects\")\n",
    "ax.set_title(\"Class Distribution in Labels\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intrepretation:**\n",
    "\n",
    "<h5>Class Imbalance Observations</h5>\n",
    "\n",
    " *  Helmet (1,787) and Motorbike (1,750) dominate the dataset → they are much more frequent than Head (293) and Person (791).\n",
    "\n",
    " *  Head is significantly underrepresented (only 293 samples), which could cause poor detection performance for this class.\n",
    "\n",
    " *  NumberPlate (1,327) is moderately represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dhash(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "hashes = {}\n",
    "duplicates = []\n",
    "\n",
    "for f in os.listdir(image_folder):\n",
    "    path = os.path.join(image_folder, f)\n",
    "    h = dhash(path)\n",
    "    if h in hashes:\n",
    "        duplicates.append((hashes[h], f))\n",
    "    else:\n",
    "        hashes[h] = f\n",
    "\n",
    "print(\"Duplicate image pairs:\", duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** There are no duplicate images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Image Properties</h3>\n",
    "    \n",
    " *  Distribution of image dimensions (width, height).\n",
    "\n",
    " *  Aspect ratio distribution (wide vs tall images).\n",
    "\n",
    " *  Check if some images are too small or too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = []\n",
    "widths = []\n",
    "aspect_ratios = []\n",
    "\n",
    "for img_name in os.listdir(image_folder):\n",
    "    path = os.path.join(image_folder, img_name)\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    if img is None:   # Skip unreadable files\n",
    "        print(\"Could not read:\", path)\n",
    "        continue\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    heights.append(h)\n",
    "    widths.append(w)\n",
    "    aspect_ratios.append(w / h)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(widths, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Width Distribution\")\n",
    "plt.xlabel(\"Width (px)\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(heights, bins=20, color=\"salmon\", edgecolor=\"black\")\n",
    "plt.title(\"Height Distribution\")\n",
    "plt.xlabel(\"Height (px)\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Aspect Ratio Distribution ---\n",
    "plt.hist(aspect_ratios, bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Aspect Ratio (Width / Height)\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Aspect Ratio Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# --- Scatter Plot (Width vs Height) ---\n",
    "plt.scatter(widths, heights, alpha=0.5, color=\"green\")\n",
    "plt.xlabel(\"Width (px)\")\n",
    "plt.ylabel(\"Height (px)\")\n",
    "plt.title(\"Image Size Distribution (Width vs Height)\")\n",
    "plt.show()\n",
    "\n",
    "# --- Check Small / Large Images ---\n",
    "too_small = [(w, h) for w, h in zip(widths, heights) if w < 100 or h < 100]\n",
    "too_large = [(w, h) for w, h in zip(widths, heights) if w > 2000 or h > 2000]\n",
    "\n",
    "print(f\"Total images: {len(widths)}\")\n",
    "print(f\"Too small images (<100 px): {len(too_small)}\")\n",
    "print(f\"Too large images (>2000 px): {len(too_large)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "\n",
    " * The dataset is well-curated, with all images being consistently sized (640x640 px), square in shape, and free of extreme outliers.\n",
    "\n",
    " * These properties are beneficial for training helmet violation detection models, minimizing the need for preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Label Analysis</h3>\n",
    "\n",
    " *  Bounding box count per image (how many objects per image).\n",
    "\n",
    " *  Class imbalance (e.g., if helmets appear much less than motorbikes, the model may be biased).\n",
    "\n",
    " *  Bounding box size distribution (are boxes tiny or very large?).\n",
    "\n",
    " *  Check for outliers (e.g., boxes outside the image boundaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store bbox sizes per class\n",
    "bbox_sizes_per_class = {cls: [] for cls in class_map.keys()}\n",
    "\n",
    "for lbl_name in os.listdir(label_folder):\n",
    "    if not lbl_name.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(label_folder, lbl_name)) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            cls = int(parts[0])\n",
    "            w, h = float(parts[3]), float(parts[4])  # normalized width, height\n",
    "            bbox_sizes_per_class[cls].append(w * h)\n",
    "\n",
    "# --- Plot per-class histograms ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cls, sizes in bbox_sizes_per_class.items():\n",
    "    if len(sizes) == 0:\n",
    "        continue\n",
    "    plt.hist(sizes, bins=30, alpha=0.6, label=class_map[cls])\n",
    "\n",
    "plt.xlabel(\"Box size (normalized area)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Bounding Box Size Distribution per Class\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Alternative: Boxplot for easier comparison ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([sizes for sizes in bbox_sizes_per_class.values()],\n",
    "            labels=[class_map[c] for c in bbox_sizes_per_class.keys()],\n",
    "            showfliers=False)  # hide extreme outliers\n",
    "plt.ylabel(\"Normalized Box Area\")\n",
    "plt.title(\"Box Size Distribution (per class)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for outliers (e.g., boxes outside the image boundaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "invalid_boxes = []\n",
    "\n",
    "for lbl_name in os.listdir(label_folder):\n",
    "    if not lbl_name.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(label_folder, lbl_name)) as f:\n",
    "        for line_num, line in enumerate(f, start=1):\n",
    "            parts = line.strip().split()\n",
    "            cls, x, y, w, h = int(parts[0]), float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "\n",
    "            # Check for invalid conditions\n",
    "            if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
    "                invalid_boxes.append((lbl_name, line_num, \"Out of [0,1] range\", parts))\n",
    "            \n",
    "            # Check if box goes outside boundaries\n",
    "            if (x - w/2) < 0 or (x + w/2) > 1 or (y - h/2) < 0 or (y + h/2) > 1:\n",
    "                invalid_boxes.append((lbl_name, line_num, \"Box exceeds image boundary\", parts))\n",
    "\n",
    "# Print results\n",
    "if invalid_boxes:\n",
    "    print(\"⚠️ Found invalid bounding boxes:\")\n",
    "    for lbl, ln, issue, box in invalid_boxes[:20]:  # show only first 20\n",
    "        print(f\"{lbl}, line {ln}: {issue} -> {box}\")\n",
    "else:\n",
    "    print(\"✅ All bounding boxes look valid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Sample Visualizations</h3>\n",
    "\n",
    " *  Randomly show images with bounding boxes (like we did earlier).\n",
    "\n",
    " *  Show some wrong labels/outliers (e.g., very small/large boxes).\n",
    "\n",
    " *  Compare images per class visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_yolo_bboxes(image_folder, label_folder, filename, class_map=None):\n",
    "    \"\"\"\n",
    "    Draw YOLO bounding boxes on a specific image and return the annotated image (RGB, np.array).\n",
    "    \"\"\"\n",
    "    # Build paths\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    label_path = os.path.join(label_folder, os.path.splitext(filename)[0] + \".txt\")\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "    colors = {0:(255,0,0),1:(0,255,0),2:(0,255,255),3:(255,165,0),4:(0,0,255)}\n",
    "    # Draw bounding boxes\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for label in f.readlines():\n",
    "                parts = label.strip().split()\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, bw, bh = map(float, parts[1:])\n",
    "                x_center, y_center, bw, bh = x_center * w, y_center * h, bw * w, bh * h\n",
    "                x1, y1 = int(x_center - bw / 2), int(y_center - bh / 2)\n",
    "                x2, y2 = int(x_center + bw / 2), int(y_center + bh / 2)\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), colors.get(class_id, (255,255,255)), 2)\n",
    "                label_text = class_map[class_id] if class_map and class_id in class_map else str(class_id)\n",
    "                cv2.putText(image, label_text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.7, colors.get(class_id, (255,255,255)), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_images_grid(image_folder, label_folder, class_map=None, N=4):\n",
    "    filenames = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
    "    random_files = random.sample(filenames, min(N, len(filenames)))\n",
    "    cols = 2\n",
    "    rows = (len(random_files) + 1) // cols\n",
    "    plt.figure(figsize=(15, 7 * rows))\n",
    "    for idx, filename in enumerate(random_files):\n",
    "        img_annotated = draw_yolo_bboxes(\n",
    "            image_folder=image_folder,\n",
    "            label_folder=label_folder,\n",
    "            filename=filename,\n",
    "            class_map=class_map\n",
    "        )\n",
    "        plt.subplot(rows, cols, idx+1)\n",
    "        plt.imshow(img_annotated)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(filename)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_images_grid(image_folder, label_folder, class_map, N=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_outlier_bboxes(image_folder, label_folder, class_map=None, min_area_ratio=0.001, max_area_ratio=0.9, N=6):\n",
    "    \"\"\"\n",
    "    Display images with outlier bounding boxes (too small or too large)\n",
    "    \n",
    "    Args:\n",
    "        image_folder: folder containing images\n",
    "        label_folder: folder containing YOLO label files\n",
    "        class_map: dict of class_id -> name\n",
    "        min_area_ratio: boxes smaller than this fraction of image area are suspicious\n",
    "        max_area_ratio: boxes larger than this fraction of image area are suspicious\n",
    "        N: number of random images to check\n",
    "    \"\"\"\n",
    "    filenames = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
    "    random_files = random.sample(filenames, min(N, len(filenames)))\n",
    "\n",
    "    plt.figure(figsize=(15, 7 * ((N+1)//2)))\n",
    "    colors = {0:(255,0,0),1:(0,255,0),2:(0,255,255),3:(255,165,0),4:(0,0,255)}\n",
    "\n",
    "    for idx, filename in enumerate(random_files):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        label_path = os.path.join(label_folder, os.path.splitext(filename)[0] + \".txt\")\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image.shape\n",
    "        image_area = h * w\n",
    "\n",
    "        # Flag boxes that are too small or too large\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for label in f.readlines():\n",
    "                    parts = label.strip().split()\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, bw, bh = map(float, parts[1:])\n",
    "                    bw_pix, bh_pix = bw*w, bh*h\n",
    "                    box_area = bw_pix * bh_pix\n",
    "\n",
    "                    if box_area/image_area < min_area_ratio or box_area/image_area > max_area_ratio:\n",
    "                        # Draw the outlier box\n",
    "                        x1, y1 = int(x_center*w - bw_pix/2), int(y_center*h - bh_pix/2)\n",
    "                        x2, y2 = int(x_center*w + bw_pix/2), int(y_center*h + bh_pix/2)\n",
    "                        cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,255), 2)  # magenta for outlier\n",
    "                        label_text = class_map[class_id] if class_map and class_id in class_map else str(class_id)\n",
    "                        cv2.putText(image, label_text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,0,255), 2)\n",
    "\n",
    "        plt.subplot((N+1)//2, 2, idx+1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(filename)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_outlier_bboxes(image_folder, label_folder, class_map, min_area_ratio=0.001, max_area_ratio=0.9, N=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_class_comparison(image_folder, label_folder, class_map=None, samples_per_class=3):\n",
    "    \"\"\"\n",
    "    Display random samples per class side by side for visual comparison.\n",
    "    \n",
    "    Args:\n",
    "        image_folder: folder containing images\n",
    "        label_folder: folder containing YOLO label files\n",
    "        class_map: dict mapping class_id -> class name\n",
    "        samples_per_class: number of examples to show per class\n",
    "    \"\"\"\n",
    "    # Collect all bounding boxes per class\n",
    "    class_boxes = {cid: [] for cid in class_map.keys()}\n",
    "\n",
    "    filenames = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
    "\n",
    "    for filename in filenames:\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        label_path = os.path.join(label_folder, os.path.splitext(filename)[0] + \".txt\")\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, bw, bh = map(float, parts[1:])\n",
    "                x1, y1 = int((x_center - bw/2) * w), int((y_center - bh/2) * h)\n",
    "                x2, y2 = int((x_center + bw/2) * w), int((y_center + bh/2) * h)\n",
    "                \n",
    "                # Crop bounding box\n",
    "                crop = image[y1:y2, x1:x2]\n",
    "                if crop.size > 0:\n",
    "                    class_boxes[class_id].append(crop)\n",
    "    \n",
    "    # Plot samples per class\n",
    "    n_classes = len(class_map)\n",
    "    plt.figure(figsize=(samples_per_class*3, n_classes*3))\n",
    "\n",
    "    for idx, class_id in enumerate(class_map.keys()):\n",
    "        samples = random.sample(class_boxes[class_id], min(samples_per_class, len(class_boxes[class_id])))\n",
    "        for s_idx, crop in enumerate(samples):\n",
    "            plt.subplot(n_classes, samples_per_class, idx*samples_per_class + s_idx + 1)\n",
    "            plt.imshow(crop)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(class_map[class_id], fontsize=8)\n",
    "            if s_idx == 0:\n",
    "                plt.ylabel(class_map[class_id], fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_class_comparison(image_folder, label_folder, class_map, samples_per_class=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h3>5. Data Quality Checks</h3>\n",
    "\n",
    " *  Blurry, duplicate, or corrupted images.\n",
    "\n",
    " *  Bounding boxes with width/height = 0.\n",
    "\n",
    " *  Check if any object is labeled incorrectly (e.g., person labeled as helmet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_corrupted_images(image_folder):\n",
    "    corrupted = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "        path = os.path.join(image_folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                corrupted.append(filename)\n",
    "        except:\n",
    "            corrupted.append(filename)\n",
    "    print(f\"Found {len(corrupted)} corrupted images\")\n",
    "    return corrupted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate_images(image_folder):\n",
    "    hashes = {}\n",
    "    duplicates = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "        path = os.path.join(image_folder, filename)\n",
    "        with open(path, 'rb') as f:\n",
    "            file_hash = hashlib.md5(f.read()).hexdigest()\n",
    "        if file_hash in hashes:\n",
    "            duplicates.append((filename, hashes[file_hash]))\n",
    "        else:\n",
    "            hashes[file_hash] = filename\n",
    "    print(f\"Found {len(duplicates)} duplicate images\")\n",
    "    return duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_blurry_images(image_folder, threshold=100.0):\n",
    "    blurry_images = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "        path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        variance = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "        if variance < threshold:\n",
    "            blurry_images.append((filename, variance))\n",
    "    print(f\"Found {len(blurry_images)} potentially blurry images\")\n",
    "    return blurry_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_invalid_bboxes(label_folder):\n",
    "    invalid_boxes = []\n",
    "    for filename in os.listdir(label_folder):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        path = os.path.join(label_folder, filename)\n",
    "        with open(path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                class_id, x_center, y_center, bw, bh = parts\n",
    "                if float(bw) <= 0 or float(bh) <= 0:\n",
    "                    invalid_boxes.append((filename, line.strip()))\n",
    "    print(f\"Found {len(invalid_boxes)} invalid bounding boxes\")\n",
    "    return invalid_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_potential_mislabeled_boxes(image_folder, label_folder, class_map, min_area_ratio=0.001, max_area_ratio=0.5):\n",
    "    suspicious = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        label_path = os.path.join(label_folder, os.path.splitext(filename)[0]+\".txt\")\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "        img = cv2.imread(image_path)\n",
    "        h, w, _ = img.shape\n",
    "        image_area = h * w\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, bw, bh = map(float, parts[1:])\n",
    "                box_area = bw * bh  # YOLO normalized\n",
    "                if box_area < min_area_ratio or box_area > max_area_ratio:\n",
    "                    suspicious.append((filename, class_map.get(class_id,str(class_id)), bw* w, bh* h))\n",
    "    print(f\"Found {len(suspicious)} potentially mislabeled boxes\")\n",
    "    return suspicious\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_4_images(issue_list, image_folder, title=\"\", duplicates=False):\n",
    "    \"\"\"\n",
    "    Display 4 sample images in a 2x2 grid.\n",
    "    \n",
    "    Args:\n",
    "        issue_list: list of image filenames (or tuples for duplicates)\n",
    "        image_folder: folder containing images\n",
    "        title: main title for the figure\n",
    "        duplicates: if True, issue_list contains tuples (dup, original)\n",
    "    \"\"\"\n",
    "    if not issue_list:\n",
    "        print(f\"No {title} found.\")\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(issue_list, min(4, len(issue_list)))\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    \n",
    "    for idx, item in enumerate(samples):\n",
    "        if duplicates:\n",
    "            filename = item[0]  # show the duplicate file\n",
    "            subtitle = f\"{item[0]}\\n(dup of {item[1]})\"\n",
    "        else:\n",
    "            if isinstance(item, tuple):  # for invalid boxes or mislabeled boxes\n",
    "                filename = item[0]\n",
    "                subtitle = f\"{os.path.basename(item[0])}\\n{item[1]}\"\n",
    "            else:\n",
    "                filename = item\n",
    "                subtitle = filename\n",
    "        \n",
    "        path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.subplot(2,2,idx+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(subtitle, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted = check_corrupted_images(image_folder)\n",
    "duplicates = check_duplicate_images(image_folder)\n",
    "blurry = check_blurry_images(image_folder)\n",
    "invalid_boxes = check_invalid_bboxes(label_folder)\n",
    "mislabeled = check_potential_mislabeled_boxes(image_folder, label_folder, class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 4 sample blurry images\n",
    "display_4_images([x[0] for x in blurry], image_folder, title=\"Blurry Images\")\n",
    "\n",
    "# Display 4 sample invalid bounding boxes\n",
    "display_4_images([x[0] for x in invalid_boxes], image_folder, title=\"Invalid Bounding Boxes\")\n",
    "\n",
    "# Display 4 sample potentially mislabeled boxes\n",
    "display_4_images([x[0] for x in mislabeled], image_folder, title=\"Potentially Mislabeled Boxes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_mislabeled_boxes(image_folder, label_folder, mislabeled_list, class_map, max_samples=4):\n",
    "    \"\"\"\n",
    "    Display potentially mislabeled boxes with bounding boxes in a 2x2 grid.\n",
    "    \n",
    "    Args:\n",
    "        image_folder: folder containing images\n",
    "        label_folder: folder containing label txt files\n",
    "        mislabeled_list: list of tuples (filename, class_name, box_width, box_height)\n",
    "        class_map: dict mapping class_id -> name\n",
    "        max_samples: maximum number of images to display\n",
    "    \"\"\"\n",
    "    if not mislabeled_list:\n",
    "        print(\"No potentially mislabeled boxes found.\")\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(mislabeled_list, min(max_samples, len(mislabeled_list)))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.suptitle(\"Potentially Mislabeled Boxes\", fontsize=16)\n",
    "    \n",
    "    colors = {0:(255,0,0),1:(0,255,0),2:(0,255,255),3:(255,165,0),4:(0,0,255)}\n",
    "\n",
    "    for idx, (filename, class_name, bw, bh) in enumerate(samples):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        label_path = os.path.join(label_folder, os.path.splitext(filename)[0]+\".txt\")\n",
    "        \n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        # Draw all bounding boxes from the label file\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    parts = line.strip().split()\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, bw_norm, bh_norm = map(float, parts[1:])\n",
    "                    x1 = int((x_center - bw_norm/2) * w)\n",
    "                    y1 = int((y_center - bh_norm/2) * h)\n",
    "                    x2 = int((x_center + bw_norm/2) * w)\n",
    "                    y2 = int((y_center + bh_norm/2) * h)\n",
    "                    # Highlight suspected mislabeled box in magenta\n",
    "                    if class_map[class_id] == class_name:\n",
    "                        color = (255,0,255)\n",
    "                        thickness = 3\n",
    "                    else:\n",
    "                        color = colors.get(class_id, (255,255,255))\n",
    "                        thickness = 2\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "                    cv2.putText(img, class_map[class_id], (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        plt.subplot(2,2,idx+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(filename, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "display_mislabeled_boxes(image_folder, label_folder, mislabeled, class_map, max_samples=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Class Co-occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. Dataset Setup\n",
    "# ==============================\n",
    "\n",
    "image_folder = \"..\\\\data\\\\raw\\\\train\\\\images\"\n",
    "label_folder = \"..\\\\data\\\\raw\\\\train\\\\labels\"\n",
    "\n",
    "# Class mapping\n",
    "class_map = {\n",
    "    0: \"NumberPlate\",\n",
    "    1: \"Person\",\n",
    "    2: \"Helmet\",\n",
    "    3: \"Head\",\n",
    "    4: \"Motorbike\"\n",
    "}\n",
    "\n",
    "# Load labels into DataFrame\n",
    "records = []\n",
    "for label_file in os.listdir(label_folder):\n",
    "    if not label_file.endswith(\".txt\"):\n",
    "        continue\n",
    "    image_id = os.path.splitext(label_file)[0]\n",
    "    img_path = os.path.join(image_folder, image_id + \".jpg\")\n",
    "    if not os.path.exists(img_path):\n",
    "        img_path = os.path.join(image_folder, image_id + \".png\")\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    with open(os.path.join(label_folder, label_file), \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_c, y_c, bw, bh = map(float, parts[1:5])\n",
    "                # Convert YOLO normalized coords to pixel coords\n",
    "                x_min = int((x_c - bw/2) * w)\n",
    "                y_min = int((y_c - bh/2) * h)\n",
    "                x_max = int((x_c + bw/2) * w)\n",
    "                y_max = int((y_c + bh/2) * h)\n",
    "                records.append([image_id, class_id, x_min, y_min, x_max, y_max, w, h])\n",
    "\n",
    "df_labels = pd.DataFrame(records, columns=[\n",
    "    \"image_id\", \"class_id\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"img_w\", \"img_h\"\n",
    "])\n",
    "df_labels[\"class_name\"] = df_labels[\"class_id\"].map(class_map)\n",
    "\n",
    "\n",
    "co_occurrence = pd.crosstab(df_labels['image_id'], df_labels['class_name'])\n",
    "co_matrix = co_occurrence.T @ co_occurrence  # class vs class matrix\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(co_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Class Co-occurrence Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What it does:** Shows which classes tend to appear together in the same image (e.g., Person + Helmet + Motorbike).\n",
    "\n",
    "**What to look for:**\n",
    "\n",
    "Are Helmet and Person co-occurring as expected?\n",
    "\n",
    "Are there images with Motorbike but no Person? (may be labeling issues)\n",
    "\n",
    "Do some classes rarely co-occur, leading to fewer “realistic” combinations in training?\n",
    "\n",
    "**Measures & Metrics:**\n",
    "\n",
    "Co-occurrence heatmap counts.\n",
    "\n",
    "Sparsity of matrix (how many class pairs are rarely seen).\n",
    "\n",
    "Imbalances (e.g., 90% of Person images also have Helmet, but only 10% without helmet → violation imbalance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moterbike + Helmet = 5877 and Moterbike + Head = 1007 : It shows that Images of persons with helmet are almost 6 times of person without helmet. So increasing images of persons without helmet in the training data will make equal distribution of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Spatial Distribution of Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels[\"x_center\"] = (df_labels[\"x_min\"] + df_labels[\"x_max\"]) / 2\n",
    "df_labels[\"y_center\"] = (df_labels[\"y_min\"] + df_labels[\"y_max\"]) / 2\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(df_labels[\"x_center\"], df_labels[\"y_center\"], alpha=0.2, s=10)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Bounding Box Center Distribution\")\n",
    "plt.xlabel(\"X Center\")\n",
    "plt.ylabel(\"Y Center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What it does:** Plots the center points of bounding boxes.\n",
    "\n",
    "**What to look for:**\n",
    "\n",
    "Are objects clustered in certain regions (e.g., bottom of image → road bias)?\n",
    "\n",
    "Are helmets mostly on the top half (where heads are), motorbikes at bottom? (logical placement check).\n",
    "\n",
    "If all bounding boxes are centered → dataset may lack variability.\n",
    "\n",
    "**Measures & Metrics:**\n",
    "\n",
    "Scatterplot density of centers.\n",
    "\n",
    "Normalized histogram of X and Y positions.\n",
    "\n",
    "Coverage % of the image area (are some regions never used?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "Most of the images bounding box distribution is around center of the image horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Occlusion & Crowding Analysis  ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Lighting & Brightness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness = []\n",
    "for img_path in glob.glob(os.path.join(image_folder, \"*.jpg\")) + glob.glob(os.path.join(image_folder, \"*.png\")):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        brightness.append(img.mean())\n",
    "\n",
    "plt.hist(brightness, bins=50)\n",
    "plt.title(\"Brightness Distribution of Images\")\n",
    "plt.xlabel(\"Average Pixel Intensity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What it does:** Checks average brightness levels of images.\n",
    "\n",
    "**What to look for:**\n",
    "\n",
    "Very dark images (night) vs very bright (daylight glare).\n",
    "\n",
    "Are all images bright? → dataset may lack nighttime conditions.\n",
    "\n",
    "Extreme outliers may be corrupted images.\n",
    "\n",
    "**Measures & Metrics:**\n",
    "\n",
    "Histogram of mean pixel intensity (0–255).\n",
    "\n",
    "Brightness variance (spread across images).\n",
    "\n",
    "% of images in “low-light” (<50 avg intensity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: Most of the images has descent brightness distribution, however certain images has less overal mean intensity which we can consider as outliers as part of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Background & Context Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "sample_imgs = glob.glob(os.path.join(image_folder, \"*.jpg\"))[:300]  # sample\n",
    "for img_path in sample_imgs:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        hist = cv2.calcHist([img], [0,1,2], None, [8,8,8], [0,256,0,256,0,256]).flatten()\n",
    "        features.append(hist)\n",
    "\n",
    "features = np.array(features)\n",
    "pca = PCA(n_components=2).fit_transform(features)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(pca)\n",
    "\n",
    "plt.scatter(pca[:,0], pca[:,1], c=kmeans.labels_, cmap=\"tab10\", alpha=0.7)\n",
    "plt.title(\"Image Clustering (Background Bias Check)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What it does:** Uses clustering (PCA + KMeans) to group images by background color/texture.\n",
    "\n",
    "**What to look for:**\n",
    "\n",
    "If clusters strongly correspond to scene type (e.g., highway vs city vs parking lot).\n",
    "\n",
    "Dataset too biased to one environment → poor generalization.\n",
    "\n",
    "If violations (no helmet) only appear in certain backgrounds → model may “cheat”.\n",
    "\n",
    "**Measures & Metrics:**\n",
    "\n",
    "Cluster purity (% images in dominant clusters).\n",
    "\n",
    "of distinct background clusters.\n",
    "\n",
    "Correlation between cluster label and class presence (bias check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short interpretation for the PCA + KMeans background clustering plot\n",
    "interpretation = (\n",
    "    \"Three distinct clusters appear, showing the dataset contains a few dominant background/color groups. \"\n",
    "    \"Clusters overlap somewhat, so some images share similar visual characteristics. \"\n",
    "    \"If certain labels (e.g., helmetless riders) are concentrated in one cluster, this indicates background bias — collect/augment images from under-represented clusters to improve generalization.\"\n",
    ")\n",
    "print(interpretation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
