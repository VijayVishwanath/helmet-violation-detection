{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "<h1 align=center><font size = 5>CAPSTONE PROJECT</font></h1>\n",
    "<h2 align=center><font size = 5>AIML Certification Programme</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Student Name and ID:\n",
    "Mention your name and ID if done individually<br>\n",
    "If done as a group,clearly mention the contribution from each group member qualitatively and as a precentage.<br>\n",
    "1. KUNA MURALI (ID: 2024AIML030)                          \n",
    "\n",
    "2. MADIRE MAHESHKUMAR (ID: 2024AIML079)\n",
    "\n",
    "3. V VIJAY KUMAR (ID: 2024AIML100)\n",
    "\n",
    "4. GADIGA MOUNESWAR BABU (ID: 2024AIML095)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helmet Violation Detection from Indian CCTV Video\n",
    "\n",
    "**Problem statement:**\n",
    "    Detect and flag two-wheeler helmet violations (helmetless riding) from traffic camera frames in Indian cities in real-time.\n",
    "\n",
    "**Description:**\n",
    "Create a computer vision system using YOLOv8 and object tracking to detect two-wheeler riders and classify helmet usage. Optionally perform license plate OCR for enforcement.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "    •\tIndian Helmet Detection Dataset\n",
    "    \n",
    "    •\tResearch-generated dataset of Indian two-wheeler violations (images+video with annotations for helmet & plate) \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python==4.9.0.80\n",
    "!pip install matplotlib==3.8.4\n",
    "!pip install numpy==1.26.4\n",
    "!pip install pillow==10.3.0\n",
    "!pip install pandas==2.2.2\n",
    "!pip install seaborn==0.13.2\n",
    "!pip install scikit-learn==1.4.2\n",
    "!pip install torch==2.3.0\n",
    "!pip install notebook==7.2.0\n",
    "!pip install albumentations==1.4.8\n",
    "!pip install albucore==0.0.16\n",
    "!pip install ultralytics==8.0.134\n",
    "!pip install --upgrade ultralytics torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import hashlib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter\n",
    "import albumentations as A\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts'))\n",
    "sys.path.append(scripts_dir)\n",
    "for entry in os.listdir(scripts_dir):\n",
    "    entry_path = os.path.join(scripts_dir, entry)\n",
    "    if os.path.isdir(entry_path):\n",
    "        sys.path.append(entry_path)\n",
    "\n",
    "from utils import show_images_grid, split_and_copy_dataset, show_random_images_grid\n",
    "from flip import HorizontalFlip\n",
    "from zoom import DynamicZoomer\n",
    "from mosaic import MosaicAugmentor\n",
    "from cutout import CutoutAugmentor\n",
    "from synthetic import SyntheticImageAugmentor\n",
    "from edgedetect import EdgeDetectAugmentor\n",
    "from cutmix import CutMixAugmentor\n",
    "from rotate import RotateAugmentor\n",
    "from shadow import ShadowCastingAugmentor\n",
    "from grayscale import GrayscaleAugmentor\n",
    "from noise import NoiseInjectionAugmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting and Copying for Train/Validation Sets\n",
    "This facilitate splitting image datasets into training and validation sets and organizing them into proper directory structures. These functions support working with datasets having corresponding label files in YOLO format.\n",
    "\n",
    "**split_and_copy_dataset**\n",
    "\n",
    "This function performs a straightforward split of a dataset into training and validation subsets based on a specified ratio, then copies images and corresponding label files to destination folders.\n",
    "\n",
    "**Workflow**:\n",
    "\n",
    "Deletes any existing data in destination folders for a clean start.\n",
    "\n",
    "Reads all images in source folder, shuffles them randomly.\n",
    "\n",
    "Splits shuffled images into training and validation sets per split_ratio.\n",
    "\n",
    "Copies images and associated label .txt files to train/val folders accordingly.\n",
    "\n",
    "Prints the count of images copied to each subset.\n",
    "\n",
    "**split_and_copy_all_processed**\n",
    "\n",
    "This function extends the above with support for multiple augmentation subfolders inside a processed root directory. It samples a fraction of images from each augmentation folder, then splits and copies them similarly.\n",
    "\n",
    "**Workflow**:\n",
    "\n",
    "Iterates over augmentation folders in processed_root.\n",
    "\n",
    "For each augmentation, samples a fraction (sample_ratio) of images randomly.\n",
    "\n",
    "Splits sampled images into train and val sets per split_ratio.\n",
    "\n",
    "Copies sampled, split images and labels to destination folders under model/train/<aug_type> and model/val/<aug_type>.\n",
    "\n",
    "Removes train- prefix in folder names before copy.\n",
    "\n",
    "Prints processed folder and counts per split.\n",
    "\n",
    "Cleans and recreates destination directories before copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_copy_dataset(\n",
    "    src_img_dir,\n",
    "    src_lbl_dir,\n",
    "    dst_train_img_dir,\n",
    "    dst_train_lbl_dir,\n",
    "    dst_val_img_dir,\n",
    "    dst_val_lbl_dir,\n",
    "    split_ratio=0.9\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits images and labels into train/val sets and copies them to destination folders.\n",
    "    \"\"\"\n",
    "    if os.path.exists(dst_train_img_dir):\n",
    "        shutil.rmtree(dst_train_img_dir)\n",
    "    if os.path.exists(dst_train_lbl_dir):\n",
    "        shutil.rmtree(dst_train_lbl_dir)\n",
    "    if os.path.exists(dst_val_img_dir):\n",
    "        shutil.rmtree(dst_val_img_dir)\n",
    "    if os.path.exists(dst_val_lbl_dir):\n",
    "        shutil.rmtree(dst_val_lbl_dir)\n",
    "    os.makedirs(dst_train_img_dir, exist_ok=True)\n",
    "    os.makedirs(dst_train_lbl_dir, exist_ok=True)\n",
    "    os.makedirs(dst_val_img_dir, exist_ok=True)\n",
    "    os.makedirs(dst_val_lbl_dir, exist_ok=True)\n",
    "\n",
    "    img_files = [f for f in os.listdir(src_img_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    random.shuffle(img_files)\n",
    "    split_idx = int(len(img_files) * split_ratio)\n",
    "    train_files = img_files[:split_idx]\n",
    "    val_files = img_files[split_idx:]\n",
    "\n",
    "    def copy_files(file_list, img_dst, lbl_dst):\n",
    "        for img_file in file_list:\n",
    "            img_src_path = os.path.join(src_img_dir, img_file)\n",
    "            lbl_src_path = os.path.join(src_lbl_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "            shutil.copy2(img_src_path, os.path.join(img_dst, img_file))\n",
    "            if os.path.exists(lbl_src_path):\n",
    "                shutil.copy2(lbl_src_path, os.path.join(lbl_dst, os.path.splitext(img_file)[0] + '.txt'))\n",
    "\n",
    "    copy_files(train_files, dst_train_img_dir, dst_train_lbl_dir)\n",
    "    copy_files(val_files, dst_val_img_dir, dst_val_lbl_dir)\n",
    "    print(f\"Copied {len(train_files)} images to train and {len(val_files)} images to val folders.\")\n",
    "\n",
    "def split_and_copy_all_processed(processed_root, dst_model_root, split_ratio=0.9, sample_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Dynamically go through all augmentation folders in processed, randomly select sample_ratio of images,\n",
    "    then split and copy to model/train and model/val. Removes 'train-' prefix from destination folder names.\n",
    "    \"\"\"\n",
    "    for aug_type in os.listdir(processed_root):\n",
    "        aug_img_dir = os.path.join(processed_root, aug_type, 'images')\n",
    "        aug_lbl_dir = os.path.join(processed_root, aug_type, 'labels')\n",
    "        if not (os.path.isdir(aug_img_dir) and os.path.isdir(aug_lbl_dir)):\n",
    "            continue\n",
    "        dst_folder = aug_type.replace('train-', '')\n",
    "        dst_train_img = os.path.join(dst_model_root, 'train', dst_folder, 'images')\n",
    "        dst_train_lbl = os.path.join(dst_model_root, 'train', dst_folder, 'labels')\n",
    "        dst_val_img = os.path.join(dst_model_root, 'val', dst_folder, 'images')\n",
    "        dst_val_lbl = os.path.join(dst_model_root, 'val', dst_folder, 'labels')\n",
    "\n",
    "        # Select a random sample of images\n",
    "        img_files = [f for f in os.listdir(aug_img_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "        sample_size = max(1, int(len(img_files) * sample_ratio))\n",
    "        sampled_files = random.sample(img_files, sample_size)\n",
    "\n",
    "        # Split sampled files into train/val\n",
    "        random.shuffle(sampled_files)\n",
    "        split_idx = int(len(sampled_files) * split_ratio)\n",
    "        train_files = sampled_files[:split_idx]\n",
    "        val_files = sampled_files[split_idx:]\n",
    "\n",
    "        def copy_files(file_list, img_dst, lbl_dst):\n",
    "            # Delete folders if they exist, then create again\n",
    "            if os.path.exists(img_dst):\n",
    "                shutil.rmtree(img_dst)\n",
    "            if os.path.exists(lbl_dst):\n",
    "                shutil.rmtree(lbl_dst)\n",
    "            os.makedirs(img_dst, exist_ok=True)\n",
    "            os.makedirs(lbl_dst, exist_ok=True)\n",
    "            for img_file in file_list:\n",
    "                img_src_path = os.path.join(aug_img_dir, img_file)\n",
    "                lbl_src_path = os.path.join(aug_lbl_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "                shutil.copy2(img_src_path, os.path.join(img_dst, img_file))\n",
    "                if os.path.exists(lbl_src_path):\n",
    "                    shutil.copy2(lbl_src_path, os.path.join(lbl_dst, os.path.splitext(img_file)[0] + '.txt'))\n",
    "\n",
    "        copy_files(train_files, dst_train_img, dst_train_lbl)\n",
    "        copy_files(val_files, dst_val_img, dst_val_lbl)\n",
    "        print(f\"Processed augmentation: {dst_folder} | Train: {len(train_files)} | Val: {len(val_files)}\")\n",
    "\n",
    "# Example usage:\n",
    "split_and_copy_dataset(\n",
    "    src_img_dir='../data/raw/train/images',\n",
    "    src_lbl_dir='../data/raw/train/labels',\n",
    "    dst_train_img_dir='../data/model/train/raw/images',\n",
    "    dst_train_lbl_dir='../data/model/train/raw/labels',\n",
    "    dst_val_img_dir='../data/model/val/raw/images',\n",
    "    dst_val_lbl_dir='../data/model/val/raw/labels',\n",
    "    split_ratio=0.9)\n",
    "\n",
    "# Example usage:\n",
    "split_and_copy_all_processed('../data/processed', '../data/model', split_ratio=0.9, sample_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Object Detection Results on Test Images\n",
    "This code snippet demonstrates how to visualize YOLOv8 model predictions alongside ground truth annotations on a sample of test images.\n",
    "\n",
    "**Workflow**\n",
    "1.  **Load Pretrained Model**\n",
    "The YOLOv8 model is loaded from saved weights located in the project directory (best.pt).\n",
    "\n",
    "2. **Prepare Test Data Paths**\n",
    "Paths to test images and their corresponding label files (in YOLO format) are specified.\n",
    "\n",
    "3. **Random Sampling of Test Images**\n",
    "A configurable number (num_images) of test images are randomly selected to display.\n",
    "\n",
    "4. **Color Coding for Bounding Boxes**\n",
    "A predefined set of RGB colors assigns unique colors to each object class for easy distinction during visualization.\n",
    "\n",
    "**Benefits**\n",
    "Allows side-by-side comparison of model output with ground truth to assess detection quality visually.\n",
    "\n",
    "Color-coded bounding boxes enable easy distinction between different object classes.\n",
    "\n",
    "Random sampling helps to get an unbiased view of model performance over the test set.\n",
    "\n",
    "**Usage**\n",
    "Modify num_images to control how many test images are visualized in each run. Ensure test image and label directories are correctly set to the dataset locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('../runs/train/motorbike_yolov8s/weights/best.pt')\n",
    "\n",
    "# Path to test images and label files\n",
    "test_img_dir = '../data/raw/test/images'\n",
    "test_label_dir = '../data/raw/test/labels'\n",
    "\n",
    "# Configure number of images to display\n",
    "num_images = 10\n",
    "\n",
    "img_files = [f for f in os.listdir(test_img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "num_images = min(num_images, len(img_files))  # Avoid exceeding available images\n",
    "selected_files = random.sample(img_files, num_images)\n",
    "\n",
    "colors = {0: (255, 0, 0), 1: (0, 255, 0), 2: (0, 255, 255), 3: (255, 165, 0), 4: (0, 0, 255)}\n",
    "\n",
    "def draw_boxes(image_path, boxes, class_ids=None):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = colors[class_ids[i]] if class_ids is not None else (255, 0, 0)\n",
    "        draw.rectangle(box, outline=color, width=2)\n",
    "    return img\n",
    "\n",
    "def read_label_file(label_file, image_path):\n",
    "    boxes = []\n",
    "    class_ids = []\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, w, h = map(float, parts[1:])\n",
    "            img_w, img_h = Image.open(image_path).size\n",
    "            x1 = (x_center - w/2) * img_w\n",
    "            y1 = (y_center - h/2) * img_h\n",
    "            x2 = (x_center + w/2) * img_w\n",
    "            y2 = (y_center + h/2) * img_h\n",
    "            boxes.append((x1, y1, x2, y2))\n",
    "            class_ids.append(class_id)\n",
    "    return boxes, class_ids\n",
    "\n",
    "fig, axes = plt.subplots(num_images, 3, figsize=(15, num_images*5))\n",
    "\n",
    "for i, img_file in enumerate(selected_files):\n",
    "    img_path = os.path.join(test_img_dir, img_file)\n",
    "    label_path = os.path.join(test_label_dir, img_file.rsplit('.', 1)[0] + '.txt')\n",
    "\n",
    "    # Original Image\n",
    "    orig_img = Image.open(img_path).convert(\"RGB\")\n",
    "    axes[i, 0].imshow(orig_img)\n",
    "    axes[i, 0].set_title(\"Original Image\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Ground Truth\n",
    "    gt_boxes, gt_classes = read_label_file(label_path, img_path)\n",
    "    img_gt = draw_boxes(img_path, gt_boxes, class_ids=gt_classes)\n",
    "    axes[i, 1].imshow(img_gt)\n",
    "    axes[i, 1].set_title(\"Ground Truth\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    # Model Prediction\n",
    "    results = model(img_path)\n",
    "    boxes_pred = results[0].boxes.xyxy.cpu().numpy()\n",
    "    class_ids_pred = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "    img_pred = draw_boxes(img_path, boxes_pred, class_ids=class_ids_pred)\n",
    "    axes[i, 2].imshow(img_pred)\n",
    "    axes[i, 2].set_title(\"Model Prediction\")\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
